{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantics and Pragmatics, KIK-LG103\n",
    "\n",
    "## Lab session 4, Part 1\n",
    "\n",
    "---\n",
    "\n",
    "In this lab session we have two main topics: **similarity** and **clustering**. Last time we learned how to work with distributed representations of meaning (vectors). Through visualizations and studying word occurences and their contexts in corpora, we tried to get an intuitive understanding of what the notion of *meaning as a vector* is all about. We also examined the notion of *similarity* visually. \n",
    "\n",
    "In this first part we will move toward more rigorous study of similarity. We will introduce a mathematical measure called **cosine similarity** and see how it relates to the visualizations we made last time.\n",
    "\n",
    "As always, let's first import some tools. The module `lab4utils` contains a few convenient functions that will be explained on the go. Run the code cell below and read on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import plot_utils\n",
    "from lab4utils import cosine_similarity, embed, get_words, \\\n",
    "                      get_mapping, get_top, plot_w2v_2d, plot_w2v_3d, \\\n",
    "                      tabulate_similarities, tabulate_angles, get_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 1.1: Problems with visualization\n",
    "---\n",
    "\n",
    "Let's start this part with a short motivating example. In the code cell below we first retrieve the 5 closests and the 5 farthest words to our target word *random*. The embeddings used are the familiar Word2Vec embeddings we saw last time. We then plot the set of words using the function `plot_w2v_3d`. \n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 1.1.1** Run the code cell below and examine the output. Pay special attention to how the different sets of words (closest/farthest) are spread out in the figure. Can you see any problems with examining word similarities using visualizations only? Can you figure out an explanation for the results?\n",
    "\n",
    "Change the word to something else and see what kinds of results you get.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a word\n",
    "word = \"random\"\n",
    "\n",
    "# Embed the word using Word2Vec\n",
    "word_embedding = embed(word)\n",
    "\n",
    "# 'get_n(embedding, n, mode)' gives us 'n' closest\n",
    "# (if mode == \"best\") or 'n' farthest (if mode == \"worst\")\n",
    "# embeddings.\n",
    "print(\"Closest:\", get_n(word_embedding, 5, \"best\"))\n",
    "print(\"Farthest:\", get_n(word_embedding, 5, \"worst\"))\n",
    "\n",
    "plot_w2v_3d(\"random randomly arbitrary anonymous deranged thorn mahogany poached statesman strides\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 1.2: Back to semantic feature analysis\n",
    "\n",
    "---\n",
    "\n",
    "Recall semantic feature analysis from last session. In the code cell below we show an example of an analysis with three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"x\": \"human\",\n",
    "    \"y\": \"adult\",\n",
    "    \"z\": \"male\"\n",
    "}\n",
    "\n",
    "# Features are binary; 0 means 'not defined'\n",
    "words = [\n",
    "    (\"girl\",  [ 1, -1, -1]),\n",
    "    (\"boy\",   [ 1, -1,  1]),\n",
    "    (\"adult\", [ 1,  1,  0]),\n",
    "    (\"woman\", [ 1,  1, -1]),\n",
    "    (\"calf\",  [-1, -1,  0]),\n",
    "    (\"cow\",   [-1,  1, -1]),\n",
    "    (\"mature\",[ 0,  1,  0])\n",
    "]\n",
    "\n",
    "plot_utils.plot_3d_binary(features, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the figure already gives us some information about the similarities (or differences) between the words, but as already mentioned, this time we want to properly quantify those similarities. In the code cell below we show you how to tabulate pairwise cosine similarities and angles for the word vectors.\n",
    "\n",
    "As a reminder: Cosine similarity is a real number (the cosine of the angle between the vectors) between `-1` and `1`. It is `1` for identical vectors, `-1` for vectors that point in completely different directions, and something inbetween for the rest. You can see the lecture slides for more information if you want. We will also dive deep into cosine similarity in Part 3 of this session.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 1.2.1** Run the code cell below, examine the output and compare the tables to the figure above.\n",
    "\n",
    "Change some of the vectors or add new ones to the list `words`. You can also also analyze some other set of words using you own features.\n",
    "\n",
    "How do the similarities and angles change when you change the vectors? Can you see how the similarities relate to the figure?\n",
    "\n",
    "Pick one word from the figure and come up with a new word so that the angle between the two is either 45°, 90°, or 180°. Figure out at least one new word for each angle.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'words' was defined in the code cell above\n",
    "tabulate_similarities(words)\n",
    "tabulate_angles(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, continue to Part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
